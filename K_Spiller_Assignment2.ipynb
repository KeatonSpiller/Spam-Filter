{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keaton Spiller \n",
    "\n",
    "CS 445 \n",
    "\n",
    "Winter 2022\n",
    "\n",
    "Assignment # 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HW_Page1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HW_Page2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File spambase.data does not exist: 'spambase.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13672/3753938077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \"char_freq_;\",\"char_freq_(\",\"char_freq_[\",\"char_freq_!\",\"char_freq_$\",\"char_freq_#\",\"capital_run_length_average\",\"capital_run_length_longest\",\"capital_run_length_total\",\"True_spam\" ]\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"spambase.data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# If we want the same permutation or \"seed\" of the data rows grabbed in different orders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File spambase.data does not exist: 'spambase.data'"
     ]
    }
   ],
   "source": [
    "index = [ 'word_freq_make',\"word_freq_address\",\"word_freq_all\",\"word_freq_3d\",\"word_freq_our\",\"word_freq_over\",\"word_freq_remove\",\"word_freq_internet\",\"word_freq_order\",       \n",
    "\"word_freq_mail\",\"word_freq_receive\",\"word_freq_will\",\"word_freq_people\",\"word_freq_report\",\"word_freq_addresses\",\"word_freq_free\",\"word_freq_business\",\"word_freq_email\",       \n",
    "\"word_freq_you\",\"word_freq_credit\",\"word_freq_your\",\"word_freq_font\",\"word_freq_000\",\"word_freq_money\",\"word_freq_hp\",\"word_freq_hpl\",\"word_freq_george\",\"word_freq_650\",         \n",
    "\"word_freq_lab\",\"word_freq_labs\",\"word_freq_telnet\",\"word_freq_857\",\"word_freq_data\",\"word_freq_415\",\"word_freq_85\",\"word_freq_technology\",\"word_freq_1999\",\"word_freq_parts\",       \n",
    "\"word_freq_pm\",\"word_freq_direct\",\"word_freq_cs\",\"word_freq_meeting\",\"word_freq_original\",\"word_freq_project\",\"word_freq_re\",\"word_freq_edu\",\"word_freq_table\",\"word_freq_conference\",  \n",
    "\"char_freq_;\",\"char_freq_(\",\"char_freq_[\",\"char_freq_!\",\"char_freq_$\",\"char_freq_#\",\"capital_run_length_average\",\"capital_run_length_longest\",\"capital_run_length_total\",\"True_spam\" ]\n",
    "\n",
    "df = pd.read_csv(\"spambase.data\", sep=\",\",names=index)\n",
    "seed = np.random.permutation(len(df)) # If we want the same permutation or \"seed\" of the data rows grabbed in different orders\n",
    "df = df.iloc[seed]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dimensions: (2300, 57)\n",
      "testing dimensions: (2301, 57)\n"
     ]
    }
   ],
   "source": [
    "true_train_class = df.iloc[:2300,-1:].to_numpy() # Seperate out the True class labels {Spam and Not_Spam}\n",
    "true_test_class = df.iloc[2300:,-1:].to_numpy()\n",
    "\n",
    "df_train = df.iloc[:2300,:-1] # ilock will split the pandas dataframe\n",
    "df_test = df.iloc[2300:,:-1] # Split the dataframe into train and test\n",
    "train = df_train.to_numpy()\n",
    "test = df_test.to_numpy()\n",
    "\n",
    "print(f\"training dimensions: {df_train.shape}\")\n",
    "print(f\"testing dimensions: {df_test.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prior_Bayes(train, true_train_class):\n",
    "    \"\"\"\n",
    "    Input train and labled classes\n",
    "    Output Spam & NonSpam prior probability, mean, and standard deviation\n",
    "    \n",
    "    \"\"\"\n",
    "    m = train.shape[0] # 2300\n",
    "    n = train.shape[1] # 57\n",
    "    spam,not_spam = [],[]\n",
    "    mean_spam = np.zeros((n,1))\n",
    "    mean_not_spam = np.zeros((n,1))\n",
    "    sd_spam = np.zeros((n,1))\n",
    "    sd_not_spam = np.zeros((n,1))\n",
    "    \n",
    "    for i, v in enumerate(train): # prior values of spam and not_spam\n",
    "        if(true_train_class[i] == 1): # class == 1 \"Spam\"\n",
    "            spam.append(v)\n",
    "            \n",
    "        if(true_train_class[i] == 0): # class == 0 \"Not_spam\"\n",
    "            not_spam.append(v)\n",
    "\n",
    "    spam = np.array(spam) # Convert to numpy arrays from a list\n",
    "    not_spam = np.array(not_spam)\n",
    "\n",
    "    # prior probabilities using count of values\n",
    "    prior_spam = len(spam)/m\n",
    "    prior_not_spam = len(not_spam)/m\n",
    "\n",
    "    # Find the mean and standard deviation of the appended true spam and non_spam values\n",
    "    mean_spam = np.mean(spam, axis=0)\n",
    "    mean_not_spam = np.mean(not_spam, axis=0)\n",
    "    sd_spam = np.std(spam, axis=0, dtype=np.float64)\n",
    "    sd_not_spam = np.std(not_spam, axis=0, dtype=np.float64)\n",
    "\n",
    "    # Replace zero's with a small value\n",
    "    sd_spam[sd_spam == 0] = 0.0001 \n",
    "    sd_not_spam[sd_not_spam == 0] = 0.0001\n",
    "\n",
    "    print(f\"{spam.shape} Spam prior probability: {prior_spam}\")\n",
    "    print(f\"{not_spam.shape} Not_Spam prior probability: {prior_not_spam}\")\n",
    "    \n",
    "    return (prior_spam, prior_not_spam, mean_spam, mean_not_spam, sd_spam, sd_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(test,train,true_test_class,true_train_class, K):\n",
    "    \"\"\"\n",
    "    Input train and test data along with labeled classes\n",
    "    Output TP TN FP FN counts of spam emails\n",
    "    \n",
    "    \"\"\"\n",
    "    m = test.shape[0]\n",
    "    n = test.shape[1]\n",
    "    True_Spam, False_Spam, True_not_spam, False_not_spam = 0,0,0,0\n",
    "    spam_probability  = np.zeros((m,1))\n",
    "    non_spam_probability = np.zeros((m,1))\n",
    "    N_not_spam = np.zeros((n,1))\n",
    "    N_spam = np.zeros((n,1))\n",
    "    prior_spam, prior_not_spam, mean_spam, mean_not_spam, sd_spam, sd_not_spam = Prior_Bayes(train, true_train_class)\n",
    "    \n",
    "    for j in range(m): # 2301 Emails\n",
    "        true_class = true_test_class[j] # True test class of current email [1 {spam}, 0 {non_spam}]\n",
    "        for i in range(n): # 57 email features\n",
    "            \n",
    "            # Spam: N = P(X|C) where N=(x; mean; sd )\n",
    "            top = -1 * ( ((test[j][i] - mean_spam[i]) ** 2) / ((2 * sd_spam[i]) ** 2) )\n",
    "            bottom = 1 / (np.sqrt(2*math.pi) * sd_spam[i])\n",
    "            N_spam[i] = np.log(((bottom + K) * (np.exp(top))), where= (((bottom + K) * (np.exp(top + 1))) != 0)) \n",
    "            if((((bottom + K) * (np.exp(top))) != 0) == 0): # check for divide by zero error\n",
    "                N_spam[i]= -math.inf\n",
    "                \n",
    "            # Non_Spam: N = P(X|C) where N=(x; mean; sd )\n",
    "            top = -1 * ( ((test[j][i] - mean_not_spam[i]) ** 2 ) /   ((2 * sd_not_spam[i]) ** 2) )\n",
    "            bottom = 1 / (np.sqrt(2*math.pi) * sd_not_spam[i])\n",
    "            N_not_spam[i] = np.log(((bottom + K) * (np.exp(top))), where= (((bottom + K) * (np.exp(top + 1))) != 0))\n",
    "            if((((bottom + K) * (np.exp(top))) != 0) == 0): # check for divide by zero error\n",
    "                N_not_spam[i]= -math.inf\n",
    "        \n",
    "        # If email has higher spam or non spam probabilities\n",
    "        # (57 Features probabilities for N_span & N_nonSpam) and fixed prior value\n",
    "        spam_probability = np.log(prior_spam) + np.sum(N_spam)\n",
    "        non_spam_probability = np.log(prior_not_spam) + np.sum(N_not_spam)\n",
    "        \n",
    "        if(true_class == 1): # Spam\n",
    "            if(spam_probability > non_spam_probability):\n",
    "                True_Spam += 1\n",
    "            if(spam_probability <= non_spam_probability):\n",
    "                False_Spam += 1\n",
    "        if(true_class == 0): # Not_Spam\n",
    "            if(non_spam_probability >= spam_probability):\n",
    "                True_not_spam += 1 \n",
    "            if(non_spam_probability < spam_probability):\n",
    "                False_not_spam += 1\n",
    "    return (True_Spam, False_Spam, True_not_spam, False_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13672/3496902547.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# K = 2300*57\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# No change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mTrue_Spam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse_Spam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue_not_spam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse_not_spam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaive_Bayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_test_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_train_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# K is laplase variation of smoothing, higher K, better the accuracy, up to 89 %\n",
    "# K = 2300*57 \n",
    "K = 0 # No change\n",
    "True_Spam, False_Spam, True_not_spam, False_not_spam = Naive_Bayes(test, train, true_test_class,true_train_class, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9122120817036071 \n",
      "Precision is : 0.9176470588235294 \n",
      "Recall is : 0.8552631578947368 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Spam</th>\n",
       "      <th>Predicted Non_Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>780.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Non_Spam</th>\n",
       "      <td>132.0</td>\n",
       "      <td>1319.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Spam  Predicted Non_Spam\n",
       "Actual Spam               780.0                70.0\n",
       "Actual Non_Spam           132.0              1319.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((2, 2))\n",
    "TP = True_Spam\n",
    "TN = True_not_spam\n",
    "FN = False_Spam\n",
    "FP = False_not_spam\n",
    "\n",
    "confusion_matrix[0][0] = TP\n",
    "confusion_matrix[0][1] = FP\n",
    "confusion_matrix[1][1] = TN\n",
    "confusion_matrix[1][0] = FN\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "print(f\"Accuracy is : {Accuracy} \")\n",
    "print(f\"Precision is : {Precision} \")\n",
    "print(f\"Recall is : {Recall} \")\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix, index = [\"Actual Spam\",\"Actual Non_Spam\"], columns=['Predicted Spam', 'Predicted Non_Spam'] )\n",
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bca8789303a82557c541726af0d1d64eda80e8d358c8bac530918a304e5e4dce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
